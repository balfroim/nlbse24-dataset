{"tours": [{"failing_test": {"className": " org.apache.commons.math.optimization.general.MinpackTest", "methodName": "testMinpackJennrichSampson", "error": "junit.framework.AssertionFailedError", "message": "expected:<0.2578330049> but was:<0.257819926636807>"}, "patched_method": {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java", "method_name": "doOptimize", "content": "    /** {@inheritDoc} */\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                    // we use the vectorial convergence checker\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }", "javadoc_start_line": 218, "annotations_start_line": 219, "method_start_line": 221, "end_line": 444}, "steps": [{"file_path": "/src/test/java/org/apache/commons/math/estimation/MinpackTest.java", "method_name": "testMinpackJennrichSampson", "content": "  public void testMinpackJennrichSampson() {\n    minpackTest(new JennrichSampsonFunction(10, new double[] { 0.3, 0.4 },\n                                            64.5856498144943, 11.1517793413499,\n                                            new double[] {\n                                             0.257819926636811, 0.257829976764542\n                                            }), false);\n  }", "javadoc_start_line": 325, "annotations_start_line": 325, "method_start_line": 325, "end_line": 331}, {"file_path": "/src/test/java/org/apache/commons/math/optimization/general/MinpackTest.java", "method_name": "testMinpackJennrichSampson", "content": "  public void testMinpackJennrichSampson() {\n    minpackTest(new JennrichSampsonFunction(10, new double[] { 0.3, 0.4 },\n                                            64.5856498144943, 11.1517793413499,\n                                            new double[] {\n                                             0.2578330049, 0.257829976764542\n                                            }), false);\n  }", "javadoc_start_line": 324, "annotations_start_line": 324, "method_start_line": 324, "end_line": 330}, {"file_path": "/src/test/java/org/apache/commons/math/estimation/MinpackTest.java", "method_name": "minpackTest", "content": "  private void minpackTest(MinpackFunction function, boolean exceptionExpected) {\n    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n    estimator.setMaxCostEval(100 * (function.getN() + 1));\n    estimator.setCostRelativeTolerance(Math.sqrt(2.22044604926e-16));\n    estimator.setParRelativeTolerance(Math.sqrt(2.22044604926e-16));\n    estimator.setOrthoTolerance(2.22044604926e-16);\n    assertTrue(function.checkTheoreticalStartCost(estimator.getRMS(function)));\n    try {\n      estimator.estimate(function);\n      assertFalse(exceptionExpected);\n    } catch (EstimationException lsse) {\n      assertTrue(exceptionExpected);\n    }\n    assertTrue(function.checkTheoreticalMinCost(estimator.getRMS(function)));\n    assertTrue(function.checkTheoreticalMinParams());\n  }", "javadoc_start_line": 490, "annotations_start_line": 490, "method_start_line": 490, "end_line": 505}, {"file_path": "/src/test/java/org/apache/commons/math/optimization/general/MinpackTest.java", "method_name": "minpackTest", "content": "  private void minpackTest(MinpackFunction function, boolean exceptionExpected) {\n      LevenbergMarquardtOptimizer optimizer = new LevenbergMarquardtOptimizer();\n      optimizer.setMaxIterations(100 * (function.getN() + 1));\n      optimizer.setCostRelativeTolerance(Math.sqrt(2.22044604926e-16));\n      optimizer.setParRelativeTolerance(Math.sqrt(2.22044604926e-16));\n      optimizer.setOrthoTolerance(2.22044604926e-16);\n//      assertTrue(function.checkTheoreticalStartCost(optimizer.getRMS()));\n      try {\n          VectorialPointValuePair optimum =\n              optimizer.optimize(function,\n                                 function.getTarget(), function.getWeight(),\n                                 function.getStartPoint());\n          assertFalse(exceptionExpected);\n          function.checkTheoreticalMinCost(optimizer.getRMS());\n          function.checkTheoreticalMinParams(optimum);\n      } catch (OptimizationException lsse) {\n          assertTrue(exceptionExpected);\n      } catch (FunctionEvaluationException fe) {\n          assertTrue(exceptionExpected);\n      }\n  }", "javadoc_start_line": 489, "annotations_start_line": 489, "method_start_line": 489, "end_line": 509}, {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/AbstractLeastSquaresOptimizer.java", "method_name": "optimize", "content": "    /** {@inheritDoc} */\n    public VectorialPointValuePair optimize(final DifferentiableMultivariateVectorialFunction f,\n                                            final double[] target, final double[] weights,\n                                            final double[] startPoint)\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        if (target.length != weights.length) {\n            throw new OptimizationException(\"dimension mismatch {0} != {1}\",\n                                            target.length, weights.length);\n        }\n\n        // reset counters\n        iterations           = 0;\n        objectiveEvaluations = 0;\n        jacobianEvaluations  = 0;\n\n        // store least squares problem characteristics\n        function         = f;\n        jF               = f.jacobian();\n        targetValues     = target.clone();\n        residualsWeights = weights.clone();\n        this.point       = startPoint.clone();\n        this.residuals   = new double[target.length];\n\n        // arrays shared with the other private methods\n        rows      = target.length;\n        cols      = point.length;\n        jacobian  = new double[rows][cols];\n\n        cost = Double.POSITIVE_INFINITY;\n\n        return doOptimize();\n\n    }", "javadoc_start_line": 323, "annotations_start_line": 324, "method_start_line": 327, "end_line": 356}, {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java", "method_name": "doOptimize", "content": "    /** {@inheritDoc} */\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                    // we use the vectorial convergence checker\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }", "javadoc_start_line": 218, "annotations_start_line": 219, "method_start_line": 221, "end_line": 444}]}, {"failing_test": {"className": " org.apache.commons.math.optimization.general.MinpackTest", "methodName": "testMinpackJennrichSampson", "error": "junit.framework.AssertionFailedError", "message": "expected:<0.2578330049> but was:<0.257819926636807>"}, "patched_method": {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java", "method_name": "LevenbergMarquardtOptimizer", "content": "    /**\n     * Build an optimizer for least squares problems.\n     * <p>The default values for the algorithm settings are:\n     *   <ul>\n     *    <li>{@link #setConvergenceChecker vectorial convergence checker}: null</li>\n     *    <li>{@link #setInitialStepBoundFactor initial step bound factor}: 100.0</li>\n     *    <li>{@link #setMaxIterations maximal iterations}: 1000</li>\n     *    <li>{@link #setCostRelativeTolerance cost relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setParRelativeTolerance parameters relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setOrthoTolerance orthogonality tolerance}: 1.0e-10</li>\n     *   </ul>\n     * </p>\n     * <p>These default values may be overridden after construction. If the {@link\n     * #setConvergenceChecker vectorial convergence checker} is set to a non-null value, it\n     * will be used instead of the {@link #setCostRelativeTolerance cost relative tolerance}\n     * and {@link #setParRelativeTolerance parameters relative tolerance} settings.\n     */\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n    }", "javadoc_start_line": 143, "annotations_start_line": 160, "method_start_line": 160, "end_line": 171}, "steps": [], "generation_failure": {"error": "Failed to generate stacktrace", "error_message": "[Errno 2] No such file or directory: './projects/Math/68/results/stacktrace-testMinpackJennrichSampson-LevenbergMarquardtOptimizer.csv'"}}, {"failing_test": {"className": " org.apache.commons.math.optimization.general.MinpackTest", "methodName": "testMinpackFreudensteinRoth", "error": "junit.framework.AssertionFailedError", "message": "expected:<11.4121122022341> but was:<11.41300466147456>"}, "patched_method": {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java", "method_name": "doOptimize", "content": "    /** {@inheritDoc} */\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                    // we use the vectorial convergence checker\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }", "javadoc_start_line": 218, "annotations_start_line": 219, "method_start_line": 221, "end_line": 444}, "steps": [{"file_path": "/src/test/java/org/apache/commons/math/estimation/MinpackTest.java", "method_name": "testMinpackFreudensteinRoth", "content": "  public void testMinpackFreudensteinRoth() {\n    minpackTest(new FreudensteinRothFunction(new double[] { 0.5, -2.0 },\n                                             20.0124960961895, 6.99887517584575,\n                                             new double[] {\n                                               11.4124844654993,\n                                               -0.896827913731509\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 5.0, -20.0 },\n                                             12432.833948863, 6.9988751744895,\n                                             new double[] {\n                                               11.4130046614746,\n                                               -0.896796038685958\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 50.0, -200.0 },\n                                             11426454.595762, 6.99887517242903,\n                                             new double[] {\n                                               11.4127817857886,\n                                               -0.89680510749204\n                                             }), false);\n  }", "javadoc_start_line": 146, "annotations_start_line": 146, "method_start_line": 146, "end_line": 165}, {"file_path": "/src/test/java/org/apache/commons/math/optimization/general/MinpackTest.java", "method_name": "testMinpackFreudensteinRoth", "content": "  public void testMinpackFreudensteinRoth() {\n    minpackTest(new FreudensteinRothFunction(new double[] { 0.5, -2.0 },\n                                             20.0124960961895, 6.99887517584575,\n                                             new double[] {\n                                               11.4124844654993,\n                                               -0.896827913731509\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 5.0, -20.0 },\n                                             12432.833948863, 6.9988751744895,\n                                             new double[] {\n                                               11.4121122022341,\n                                               -0.8968550851268697\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 50.0, -200.0 },\n                                             11426454.595762, 6.99887517242903,\n                                             new double[] {\n                                               11.412069435091231,\n                                               -0.8968582807605691\n                                             }), false);\n  }", "javadoc_start_line": 145, "annotations_start_line": 145, "method_start_line": 145, "end_line": 164}, {"file_path": "/src/test/java/org/apache/commons/math/estimation/MinpackTest.java", "method_name": "minpackTest", "content": "  private void minpackTest(MinpackFunction function, boolean exceptionExpected) {\n    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n    estimator.setMaxCostEval(100 * (function.getN() + 1));\n    estimator.setCostRelativeTolerance(Math.sqrt(2.22044604926e-16));\n    estimator.setParRelativeTolerance(Math.sqrt(2.22044604926e-16));\n    estimator.setOrthoTolerance(2.22044604926e-16);\n    assertTrue(function.checkTheoreticalStartCost(estimator.getRMS(function)));\n    try {\n      estimator.estimate(function);\n      assertFalse(exceptionExpected);\n    } catch (EstimationException lsse) {\n      assertTrue(exceptionExpected);\n    }\n    assertTrue(function.checkTheoreticalMinCost(estimator.getRMS(function)));\n    assertTrue(function.checkTheoreticalMinParams());\n  }", "javadoc_start_line": 490, "annotations_start_line": 490, "method_start_line": 490, "end_line": 505}, {"file_path": "/src/test/java/org/apache/commons/math/optimization/general/MinpackTest.java", "method_name": "minpackTest", "content": "  private void minpackTest(MinpackFunction function, boolean exceptionExpected) {\n      LevenbergMarquardtOptimizer optimizer = new LevenbergMarquardtOptimizer();\n      optimizer.setMaxIterations(100 * (function.getN() + 1));\n      optimizer.setCostRelativeTolerance(Math.sqrt(2.22044604926e-16));\n      optimizer.setParRelativeTolerance(Math.sqrt(2.22044604926e-16));\n      optimizer.setOrthoTolerance(2.22044604926e-16);\n//      assertTrue(function.checkTheoreticalStartCost(optimizer.getRMS()));\n      try {\n          VectorialPointValuePair optimum =\n              optimizer.optimize(function,\n                                 function.getTarget(), function.getWeight(),\n                                 function.getStartPoint());\n          assertFalse(exceptionExpected);\n          function.checkTheoreticalMinCost(optimizer.getRMS());\n          function.checkTheoreticalMinParams(optimum);\n      } catch (OptimizationException lsse) {\n          assertTrue(exceptionExpected);\n      } catch (FunctionEvaluationException fe) {\n          assertTrue(exceptionExpected);\n      }\n  }", "javadoc_start_line": 489, "annotations_start_line": 489, "method_start_line": 489, "end_line": 509}, {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/AbstractLeastSquaresOptimizer.java", "method_name": "optimize", "content": "    /** {@inheritDoc} */\n    public VectorialPointValuePair optimize(final DifferentiableMultivariateVectorialFunction f,\n                                            final double[] target, final double[] weights,\n                                            final double[] startPoint)\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        if (target.length != weights.length) {\n            throw new OptimizationException(\"dimension mismatch {0} != {1}\",\n                                            target.length, weights.length);\n        }\n\n        // reset counters\n        iterations           = 0;\n        objectiveEvaluations = 0;\n        jacobianEvaluations  = 0;\n\n        // store least squares problem characteristics\n        function         = f;\n        jF               = f.jacobian();\n        targetValues     = target.clone();\n        residualsWeights = weights.clone();\n        this.point       = startPoint.clone();\n        this.residuals   = new double[target.length];\n\n        // arrays shared with the other private methods\n        rows      = target.length;\n        cols      = point.length;\n        jacobian  = new double[rows][cols];\n\n        cost = Double.POSITIVE_INFINITY;\n\n        return doOptimize();\n\n    }", "javadoc_start_line": 323, "annotations_start_line": 324, "method_start_line": 327, "end_line": 356}, {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java", "method_name": "doOptimize", "content": "    /** {@inheritDoc} */\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        while (true) {\n\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return new VectorialPointValuePair(point, objective);\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n\n                // tests for convergence.\n                    // we use the vectorial convergence checker\n                    // we use the Levenberg-Marquardt specific convergence parameters\n                    if (((Math.abs(actRed) <= costRelativeTolerance) &&\n                         (preRed <= costRelativeTolerance) &&\n                         (ratio <= 2.0)) ||\n                        (delta <= parRelativeTolerance * xNorm)) {\n                        return new VectorialPointValuePair(point, objective);\n                    }\n\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(\"cost relative tolerance is too small ({0}),\" +\n                            \" no further reduction in the\" +\n                            \" sum of squares is possible\",\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(\"parameters relative tolerance is too small\" +\n                            \" ({0}), no further improvement in\" +\n                            \" the approximate solution is possible\",\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(\"orthogonality tolerance is too small ({0}),\" +\n                            \" solution is orthogonal to the jacobian\",\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }", "javadoc_start_line": 218, "annotations_start_line": 219, "method_start_line": 221, "end_line": 444}]}, {"failing_test": {"className": " org.apache.commons.math.optimization.general.MinpackTest", "methodName": "testMinpackFreudensteinRoth", "error": "junit.framework.AssertionFailedError", "message": "expected:<11.4121122022341> but was:<11.41300466147456>"}, "patched_method": {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java", "method_name": "LevenbergMarquardtOptimizer", "content": "    /**\n     * Build an optimizer for least squares problems.\n     * <p>The default values for the algorithm settings are:\n     *   <ul>\n     *    <li>{@link #setConvergenceChecker vectorial convergence checker}: null</li>\n     *    <li>{@link #setInitialStepBoundFactor initial step bound factor}: 100.0</li>\n     *    <li>{@link #setMaxIterations maximal iterations}: 1000</li>\n     *    <li>{@link #setCostRelativeTolerance cost relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setParRelativeTolerance parameters relative tolerance}: 1.0e-10</li>\n     *    <li>{@link #setOrthoTolerance orthogonality tolerance}: 1.0e-10</li>\n     *   </ul>\n     * </p>\n     * <p>These default values may be overridden after construction. If the {@link\n     * #setConvergenceChecker vectorial convergence checker} is set to a non-null value, it\n     * will be used instead of the {@link #setCostRelativeTolerance cost relative tolerance}\n     * and {@link #setParRelativeTolerance parameters relative tolerance} settings.\n     */\n    public LevenbergMarquardtOptimizer() {\n\n        // set up the superclass with a default  max cost evaluations setting\n        setMaxIterations(1000);\n\n        // default values for the tuning parameters\n        setInitialStepBoundFactor(100.0);\n        setCostRelativeTolerance(1.0e-10);\n        setParRelativeTolerance(1.0e-10);\n        setOrthoTolerance(1.0e-10);\n\n    }", "javadoc_start_line": 143, "annotations_start_line": 160, "method_start_line": 160, "end_line": 171}, "steps": [], "generation_failure": {"error": "Failed to generate stacktrace", "error_message": "[Errno 2] No such file or directory: './projects/Math/68/results/stacktrace-testMinpackFreudensteinRoth-LevenbergMarquardtOptimizer.csv'"}}], "project": {"name": "Math", "version": 68}}