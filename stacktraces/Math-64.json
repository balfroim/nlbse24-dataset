{"tours": [{"failing_test": {"className": " org.apache.commons.math.optimization.general.MinpackTest", "methodName": "testMinpackJennrichSampson", "error": "junit.framework.AssertionFailedError", "message": "expected:<0.2578199266368004> but was:<0.2578330049004441>"}, "patched_method": {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java", "method_name": "doOptimize", "content": "    /** {@inheritDoc} */\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n        while (true) {\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            VectorialPointValuePair previous = current;\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return current;\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n                current = new VectorialPointValuePair(point, objective);\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n\n                    // tests for convergence.\n                    // we use the vectorial convergence checker\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n                if (checker==null) {\n                \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n                        (preRed <= costRelativeTolerance) &&\n                        (ratio <= 2.0)) ||\n                       (delta <= parRelativeTolerance * xNorm)) {\n                       return current;\n                   }\n                } else {\n                    if (checker.converged(getIterations(), previous, current)) {\n                        return current;\n                    }\n                }\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }", "javadoc_start_line": 239, "annotations_start_line": 240, "method_start_line": 242, "end_line": 464}, "steps": [{"file_path": "/src/test/java/org/apache/commons/math/estimation/MinpackTest.java", "method_name": "testMinpackJennrichSampson", "content": "  public void testMinpackJennrichSampson() {\n    minpackTest(new JennrichSampsonFunction(10, new double[] { 0.3, 0.4 },\n                                            64.5856498144943, 11.1517793413499,\n                                            new double[] {\n                                             0.257819926636811, 0.257829976764542\n                                            }), false);\n  }", "javadoc_start_line": 325, "annotations_start_line": 325, "method_start_line": 325, "end_line": 331}, {"file_path": "/src/test/java/org/apache/commons/math/optimization/general/MinpackTest.java", "method_name": "testMinpackJennrichSampson", "content": "  public void testMinpackJennrichSampson() {\n    minpackTest(new JennrichSampsonFunction(10, new double[] { 0.3, 0.4 },\n                                            64.5856498144943, 11.1517793413499,\n                                            new double[] {\n //                                            0.2578330049, 0.257829976764542\n                                               0.2578199266368004, 0.25782997676455244\n                                            }), false);\n  }", "javadoc_start_line": 324, "annotations_start_line": 324, "method_start_line": 324, "end_line": 331}, {"file_path": "/src/test/java/org/apache/commons/math/estimation/MinpackTest.java", "method_name": "minpackTest", "content": "  private void minpackTest(MinpackFunction function, boolean exceptionExpected) {\n    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n    estimator.setMaxCostEval(100 * (function.getN() + 1));\n    estimator.setCostRelativeTolerance(Math.sqrt(2.22044604926e-16));\n    estimator.setParRelativeTolerance(Math.sqrt(2.22044604926e-16));\n    estimator.setOrthoTolerance(2.22044604926e-16);\n    assertTrue(function.checkTheoreticalStartCost(estimator.getRMS(function)));\n    try {\n      estimator.estimate(function);\n      assertFalse(exceptionExpected);\n    } catch (EstimationException lsse) {\n      assertTrue(exceptionExpected);\n    }\n    assertTrue(function.checkTheoreticalMinCost(estimator.getRMS(function)));\n    assertTrue(function.checkTheoreticalMinParams());\n  }", "javadoc_start_line": 490, "annotations_start_line": 490, "method_start_line": 490, "end_line": 505}, {"file_path": "/src/test/java/org/apache/commons/math/optimization/general/MinpackTest.java", "method_name": "minpackTest", "content": "  private void minpackTest(MinpackFunction function, boolean exceptionExpected) {\n      LevenbergMarquardtOptimizer optimizer = new LevenbergMarquardtOptimizer();\n      optimizer.setMaxIterations(100 * (function.getN() + 1));\n      optimizer.setCostRelativeTolerance(Math.sqrt(2.22044604926e-16));\n      optimizer.setParRelativeTolerance(Math.sqrt(2.22044604926e-16));\n      optimizer.setOrthoTolerance(2.22044604926e-16);\n//      assertTrue(function.checkTheoreticalStartCost(optimizer.getRMS()));\n      try {\n          VectorialPointValuePair optimum =\n              optimizer.optimize(function,\n                                 function.getTarget(), function.getWeight(),\n                                 function.getStartPoint());\n          assertFalse(exceptionExpected);\n          function.checkTheoreticalMinCost(optimizer.getRMS());\n          function.checkTheoreticalMinParams(optimum);\n      } catch (OptimizationException lsse) {\n          assertTrue(exceptionExpected);\n      } catch (FunctionEvaluationException fe) {\n          assertTrue(exceptionExpected);\n      }\n  }", "javadoc_start_line": 490, "annotations_start_line": 490, "method_start_line": 490, "end_line": 510}, {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/AbstractLeastSquaresOptimizer.java", "method_name": "optimize", "content": "    /** {@inheritDoc} */\n    public VectorialPointValuePair optimize(final DifferentiableMultivariateVectorialFunction f,\n                                            final double[] target, final double[] weights,\n                                            final double[] startPoint)\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        if (target.length != weights.length) {\n            throw new OptimizationException(LocalizedFormats.DIMENSIONS_MISMATCH_SIMPLE,\n                                            target.length, weights.length);\n        }\n\n        // reset counters\n        iterations           = 0;\n        objectiveEvaluations = 0;\n        jacobianEvaluations  = 0;\n\n        // store least squares problem characteristics\n        function         = f;\n        jF               = f.jacobian();\n        targetValues     = target.clone();\n        residualsWeights = weights.clone();\n        this.point       = startPoint.clone();\n        this.residuals   = new double[target.length];\n\n        // arrays shared with the other private methods\n        rows      = target.length;\n        cols      = point.length;\n        jacobian  = new double[rows][cols];\n\n        cost = Double.POSITIVE_INFINITY;\n\n        return doOptimize();\n\n    }", "javadoc_start_line": 316, "annotations_start_line": 317, "method_start_line": 320, "end_line": 349}, {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java", "method_name": "doOptimize", "content": "    /** {@inheritDoc} */\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n        while (true) {\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            VectorialPointValuePair previous = current;\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return current;\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n                current = new VectorialPointValuePair(point, objective);\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n\n                    // tests for convergence.\n                    // we use the vectorial convergence checker\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n                if (checker==null) {\n                \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n                        (preRed <= costRelativeTolerance) &&\n                        (ratio <= 2.0)) ||\n                       (delta <= parRelativeTolerance * xNorm)) {\n                       return current;\n                   }\n                } else {\n                    if (checker.converged(getIterations(), previous, current)) {\n                        return current;\n                    }\n                }\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }", "javadoc_start_line": 239, "annotations_start_line": 240, "method_start_line": 242, "end_line": 464}]}, {"failing_test": {"className": " org.apache.commons.math.optimization.general.MinpackTest", "methodName": "testMinpackFreudensteinRoth", "error": "junit.framework.AssertionFailedError", "message": "expected:<11.41300466147456> but was:<11.4121122022341>"}, "patched_method": {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java", "method_name": "doOptimize", "content": "    /** {@inheritDoc} */\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n        while (true) {\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            VectorialPointValuePair previous = current;\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return current;\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n                current = new VectorialPointValuePair(point, objective);\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n\n                    // tests for convergence.\n                    // we use the vectorial convergence checker\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n                if (checker==null) {\n                \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n                        (preRed <= costRelativeTolerance) &&\n                        (ratio <= 2.0)) ||\n                       (delta <= parRelativeTolerance * xNorm)) {\n                       return current;\n                   }\n                } else {\n                    if (checker.converged(getIterations(), previous, current)) {\n                        return current;\n                    }\n                }\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }", "javadoc_start_line": 239, "annotations_start_line": 240, "method_start_line": 242, "end_line": 464}, "steps": [{"file_path": "/src/test/java/org/apache/commons/math/estimation/MinpackTest.java", "method_name": "testMinpackFreudensteinRoth", "content": "  public void testMinpackFreudensteinRoth() {\n    minpackTest(new FreudensteinRothFunction(new double[] { 0.5, -2.0 },\n                                             20.0124960961895, 6.99887517584575,\n                                             new double[] {\n                                               11.4124844654993,\n                                               -0.896827913731509\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 5.0, -20.0 },\n                                             12432.833948863, 6.9988751744895,\n                                             new double[] {\n                                               11.4130046614746,\n                                               -0.896796038685958\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 50.0, -200.0 },\n                                             11426454.595762, 6.99887517242903,\n                                             new double[] {\n                                               11.4127817857886,\n                                               -0.89680510749204\n                                             }), false);\n  }", "javadoc_start_line": 146, "annotations_start_line": 146, "method_start_line": 146, "end_line": 165}, {"file_path": "/src/test/java/org/apache/commons/math/optimization/general/MinpackTest.java", "method_name": "testMinpackFreudensteinRoth", "content": "  public void testMinpackFreudensteinRoth() {\n    minpackTest(new FreudensteinRothFunction(new double[] { 0.5, -2.0 },\n                                             20.0124960961895, 6.99887517584575,\n                                             new double[] {\n                                               11.4124844654993,\n                                               -0.896827913731509\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 5.0, -20.0 },\n                                             12432.833948863, 6.9988751744895,\n                                             new double[] {\n                                                11.41300466147456,\n                                                -0.896796038685959\n                                             }), false);\n    minpackTest(new FreudensteinRothFunction(new double[] { 50.0, -200.0 },\n                                             11426454.595762, 6.99887517242903,\n                                             new double[] {\n                                                 11.412781785788564,\n                                                 -0.8968051074920405\n                                             }), false);\n  }", "javadoc_start_line": 145, "annotations_start_line": 145, "method_start_line": 145, "end_line": 164}, {"file_path": "/src/test/java/org/apache/commons/math/estimation/MinpackTest.java", "method_name": "minpackTest", "content": "  private void minpackTest(MinpackFunction function, boolean exceptionExpected) {\n    LevenbergMarquardtEstimator estimator = new LevenbergMarquardtEstimator();\n    estimator.setMaxCostEval(100 * (function.getN() + 1));\n    estimator.setCostRelativeTolerance(Math.sqrt(2.22044604926e-16));\n    estimator.setParRelativeTolerance(Math.sqrt(2.22044604926e-16));\n    estimator.setOrthoTolerance(2.22044604926e-16);\n    assertTrue(function.checkTheoreticalStartCost(estimator.getRMS(function)));\n    try {\n      estimator.estimate(function);\n      assertFalse(exceptionExpected);\n    } catch (EstimationException lsse) {\n      assertTrue(exceptionExpected);\n    }\n    assertTrue(function.checkTheoreticalMinCost(estimator.getRMS(function)));\n    assertTrue(function.checkTheoreticalMinParams());\n  }", "javadoc_start_line": 490, "annotations_start_line": 490, "method_start_line": 490, "end_line": 505}, {"file_path": "/src/test/java/org/apache/commons/math/optimization/general/MinpackTest.java", "method_name": "minpackTest", "content": "  private void minpackTest(MinpackFunction function, boolean exceptionExpected) {\n      LevenbergMarquardtOptimizer optimizer = new LevenbergMarquardtOptimizer();\n      optimizer.setMaxIterations(100 * (function.getN() + 1));\n      optimizer.setCostRelativeTolerance(Math.sqrt(2.22044604926e-16));\n      optimizer.setParRelativeTolerance(Math.sqrt(2.22044604926e-16));\n      optimizer.setOrthoTolerance(2.22044604926e-16);\n//      assertTrue(function.checkTheoreticalStartCost(optimizer.getRMS()));\n      try {\n          VectorialPointValuePair optimum =\n              optimizer.optimize(function,\n                                 function.getTarget(), function.getWeight(),\n                                 function.getStartPoint());\n          assertFalse(exceptionExpected);\n          function.checkTheoreticalMinCost(optimizer.getRMS());\n          function.checkTheoreticalMinParams(optimum);\n      } catch (OptimizationException lsse) {\n          assertTrue(exceptionExpected);\n      } catch (FunctionEvaluationException fe) {\n          assertTrue(exceptionExpected);\n      }\n  }", "javadoc_start_line": 490, "annotations_start_line": 490, "method_start_line": 490, "end_line": 510}, {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/AbstractLeastSquaresOptimizer.java", "method_name": "optimize", "content": "    /** {@inheritDoc} */\n    public VectorialPointValuePair optimize(final DifferentiableMultivariateVectorialFunction f,\n                                            final double[] target, final double[] weights,\n                                            final double[] startPoint)\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        if (target.length != weights.length) {\n            throw new OptimizationException(LocalizedFormats.DIMENSIONS_MISMATCH_SIMPLE,\n                                            target.length, weights.length);\n        }\n\n        // reset counters\n        iterations           = 0;\n        objectiveEvaluations = 0;\n        jacobianEvaluations  = 0;\n\n        // store least squares problem characteristics\n        function         = f;\n        jF               = f.jacobian();\n        targetValues     = target.clone();\n        residualsWeights = weights.clone();\n        this.point       = startPoint.clone();\n        this.residuals   = new double[target.length];\n\n        // arrays shared with the other private methods\n        rows      = target.length;\n        cols      = point.length;\n        jacobian  = new double[rows][cols];\n\n        cost = Double.POSITIVE_INFINITY;\n\n        return doOptimize();\n\n    }", "javadoc_start_line": 316, "annotations_start_line": 317, "method_start_line": 320, "end_line": 349}, {"file_path": "/src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java", "method_name": "doOptimize", "content": "    /** {@inheritDoc} */\n    @Override\n    protected VectorialPointValuePair doOptimize()\n        throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {\n\n        // arrays shared with the other private methods\n        solvedCols  = Math.min(rows, cols);\n        diagR       = new double[cols];\n        jacNorm     = new double[cols];\n        beta        = new double[cols];\n        permutation = new int[cols];\n        lmDir       = new double[cols];\n\n        // local point\n        double   delta   = 0;\n        double   xNorm   = 0;\n        double[] diag    = new double[cols];\n        double[] oldX    = new double[cols];\n        double[] oldRes  = new double[rows];\n        double[] work1   = new double[cols];\n        double[] work2   = new double[cols];\n        double[] work3   = new double[cols];\n\n        // evaluate the function at the starting point and calculate its norm\n        updateResidualsAndCost();\n\n        // outer loop\n        lmPar = 0;\n        boolean firstIteration = true;\n        VectorialPointValuePair current = new VectorialPointValuePair(point, objective);\n        while (true) {\n            incrementIterationsCounter();\n\n            // compute the Q.R. decomposition of the jacobian matrix\n            VectorialPointValuePair previous = current;\n            updateJacobian();\n            qrDecomposition();\n\n            // compute Qt.res\n            qTy(residuals);\n            // now we don't need Q anymore,\n            // so let jacobian contain the R matrix with its diagonal elements\n            for (int k = 0; k < solvedCols; ++k) {\n                int pk = permutation[k];\n                jacobian[k][pk] = diagR[pk];\n            }\n\n            if (firstIteration) {\n\n                // scale the point according to the norms of the columns\n                // of the initial jacobian\n                xNorm = 0;\n                for (int k = 0; k < cols; ++k) {\n                    double dk = jacNorm[k];\n                    if (dk == 0) {\n                        dk = 1.0;\n                    }\n                    double xk = dk * point[k];\n                    xNorm  += xk * xk;\n                    diag[k] = dk;\n                }\n                xNorm = Math.sqrt(xNorm);\n\n                // initialize the step bound delta\n                delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n\n            }\n\n            // check orthogonality between function vector and jacobian columns\n            double maxCosine = 0;\n            if (cost != 0) {\n                for (int j = 0; j < solvedCols; ++j) {\n                    int    pj = permutation[j];\n                    double s  = jacNorm[pj];\n                    if (s != 0) {\n                        double sum = 0;\n                        for (int i = 0; i <= j; ++i) {\n                            sum += jacobian[i][pj] * residuals[i];\n                        }\n                        maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));\n                    }\n                }\n            }\n            if (maxCosine <= orthoTolerance) {\n                // convergence has been reached\n                return current;\n            }\n\n            // rescale if necessary\n            for (int j = 0; j < cols; ++j) {\n                diag[j] = Math.max(diag[j], jacNorm[j]);\n            }\n\n            // inner loop\n            for (double ratio = 0; ratio < 1.0e-4;) {\n\n                // save the state\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    oldX[pj] = point[pj];\n                }\n                double previousCost = cost;\n                double[] tmpVec = residuals;\n                residuals = oldRes;\n                oldRes    = tmpVec;\n\n                // determine the Levenberg-Marquardt parameter\n                determineLMParameter(oldRes, delta, diag, work1, work2, work3);\n\n                // compute the new point and the norm of the evolution direction\n                double lmNorm = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    lmDir[pj] = -lmDir[pj];\n                    point[pj] = oldX[pj] + lmDir[pj];\n                    double s = diag[pj] * lmDir[pj];\n                    lmNorm  += s * s;\n                }\n                lmNorm = Math.sqrt(lmNorm);\n                // on the first iteration, adjust the initial step bound.\n                if (firstIteration) {\n                    delta = Math.min(delta, lmNorm);\n                }\n\n                // evaluate the function at x + p and calculate its norm\n                updateResidualsAndCost();\n                current = new VectorialPointValuePair(point, objective);\n\n                // compute the scaled actual reduction\n                double actRed = -1.0;\n                if (0.1 * cost < previousCost) {\n                    double r = cost / previousCost;\n                    actRed = 1.0 - r * r;\n                }\n\n                // compute the scaled predicted reduction\n                // and the scaled directional derivative\n                for (int j = 0; j < solvedCols; ++j) {\n                    int pj = permutation[j];\n                    double dirJ = lmDir[pj];\n                    work1[j] = 0;\n                    for (int i = 0; i <= j; ++i) {\n                        work1[i] += jacobian[i][pj] * dirJ;\n                    }\n                }\n                double coeff1 = 0;\n                for (int j = 0; j < solvedCols; ++j) {\n                    coeff1 += work1[j] * work1[j];\n                }\n                double pc2 = previousCost * previousCost;\n                coeff1 = coeff1 / pc2;\n                double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n                double preRed = coeff1 + 2 * coeff2;\n                double dirDer = -(coeff1 + coeff2);\n\n                // ratio of the actual to the predicted reduction\n                ratio = (preRed == 0) ? 0 : (actRed / preRed);\n\n                // update the step bound\n                if (ratio <= 0.25) {\n                    double tmp =\n                        (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n                        if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\n                            tmp = 0.1;\n                        }\n                        delta = tmp * Math.min(delta, 10.0 * lmNorm);\n                        lmPar /= tmp;\n                } else if ((lmPar == 0) || (ratio >= 0.75)) {\n                    delta = 2 * lmNorm;\n                    lmPar *= 0.5;\n                }\n\n                // test for successful iteration.\n                if (ratio >= 1.0e-4) {\n                    // successful iteration, update the norm\n                    firstIteration = false;\n                    xNorm = 0;\n                    for (int k = 0; k < cols; ++k) {\n                        double xK = diag[k] * point[k];\n                        xNorm    += xK * xK;\n                    }\n                    xNorm = Math.sqrt(xNorm);\n\n                    // tests for convergence.\n                    // we use the vectorial convergence checker\n                } else {\n                    // failed iteration, reset the previous values\n                    cost = previousCost;\n                    for (int j = 0; j < solvedCols; ++j) {\n                        int pj = permutation[j];\n                        point[pj] = oldX[pj];\n                    }\n                    tmpVec    = residuals;\n                    residuals = oldRes;\n                    oldRes    = tmpVec;\n                }\n                if (checker==null) {\n                \tif (((Math.abs(actRed) <= costRelativeTolerance) &&\n                        (preRed <= costRelativeTolerance) &&\n                        (ratio <= 2.0)) ||\n                       (delta <= parRelativeTolerance * xNorm)) {\n                       return current;\n                   }\n                } else {\n                    if (checker.converged(getIterations(), previous, current)) {\n                        return current;\n                    }\n                }\n                // tests for termination and stringent tolerances\n                // (2.2204e-16 is the machine epsilon for IEEE754)\n                if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE,\n                            costRelativeTolerance);\n                } else if (delta <= 2.2204e-16 * xNorm) {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE,\n                            parRelativeTolerance);\n                } else if (maxCosine <= 2.2204e-16)  {\n                    throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE,\n                            orthoTolerance);\n                }\n\n            }\n\n        }\n\n    }", "javadoc_start_line": 239, "annotations_start_line": 240, "method_start_line": 242, "end_line": 464}]}], "project": {"name": "Math", "version": 64}}