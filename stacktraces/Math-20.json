{"tours": [{"failing_test": {"className": " org.apache.commons.math3.optimization.direct.CMAESOptimizerTest", "methodName": "testMath864", "error": "junit.framework.AssertionFailedError", "message": "Out of bounds (0.7651312169618905 > 0.5)"}, "patched_method": {"file_path": "/src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java", "method_name": "repairAndDecode", "content": "        /**\n         * @param x Normalized objective variables.\n         * @return the original objective variables, possibly repaired.\n         */\n        public double[] repairAndDecode(final double[] x) {\n            return\n                decode(x);\n        }", "javadoc_start_line": 916, "annotations_start_line": 920, "method_start_line": 920, "end_line": 923}, "steps": [{"file_path": "/src/test/java/org/apache/commons/math3/optimization/direct/CMAESOptimizerTest.java", "method_name": "testMath864", "content": "    public void testMath864() {\n        final CMAESOptimizer optimizer = new CMAESOptimizer();\n        final MultivariateFunction fitnessFunction = new MultivariateFunction() {\n                @Override\n                public double value(double[] parameters) {\n                    final double target = 1;\n                    final double error = target - parameters[0];\n                    return error * error;\n                }\n            };\n\n        final double[] start = { 0 };\n        final double[] lower = { -1e6 };\n        final double[] upper = { 0.5 };\n        final double[] result = optimizer.optimize(10000, fitnessFunction, GoalType.MINIMIZE,\n                                                   start, lower, upper).getPoint();\n        Assert.assertTrue(\"Out of bounds (\" + result[0] + \" > \" + upper[0] + \")\",\n                          result[0] <= upper[0]);\n    }", "javadoc_start_line": 384, "annotations_start_line": 383, "method_start_line": 384, "end_line": 402}, {"file_path": "/src/main/java/org/apache/commons/math3/optimization/direct/BaseAbstractMultivariateSimpleBoundsOptimizer.java", "method_name": "optimize", "content": "    /** {@inheritDoc} */\n    public PointValuePair optimize(int maxEval, FUNC f, GoalType goalType,\n                                       double[] startPoint,\n                                       double[] lower, double[] upper) {\n        // Checks.\n        final int dim = startPoint.length;\n        if (lower != null) {\n            if (lower.length != dim) {\n                throw new DimensionMismatchException(lower.length, dim);\n            }\n            for (int i = 0; i < dim; i++) {\n                final double v = startPoint[i];\n                final double lo = lower[i];\n                if (v < lo) {\n                    throw new NumberIsTooSmallException(v, lo, true);\n                }\n            }\n        }\n        if (upper != null) {\n            if (upper.length != dim) {\n                throw new DimensionMismatchException(upper.length, dim);\n            }\n            for (int i = 0; i < dim; i++) {\n                final double v = startPoint[i];\n                final double hi = upper[i];\n                if (v > hi) {\n                    throw new NumberIsTooLargeException(v, hi, true);\n                }\n            }\n        }\n\n        // Initialization.\n        if (lower == null) {\n            lowerBound = new double[dim];\n            for (int i = 0; i < dim; i++) {\n                lowerBound[i] = Double.NEGATIVE_INFINITY;\n            }\n        } else {\n            lowerBound = lower.clone();\n        }\n        if (upper == null) {\n            upperBound = new double[dim];\n            for (int i = 0; i < dim; i++) {\n                upperBound[i] = Double.POSITIVE_INFINITY;\n            }\n        } else {\n            upperBound = upper.clone();\n        }\n\n        // Base class method performs the non bound-specific initializations.\n        return super.optimize(maxEval, f, goalType, startPoint);\n    }", "javadoc_start_line": 90, "annotations_start_line": 91, "method_start_line": 93, "end_line": 141}, {"file_path": "/src/main/java/org/apache/commons/math3/optimization/direct/BaseAbstractMultivariateOptimizer.java", "method_name": "optimize", "content": "    /** {@inheritDoc} */\n    public PointValuePair optimize(int maxEval, FUNC f, GoalType goalType,\n                                       double[] startPoint) {\n        return optimizeInternal(maxEval, f, goalType, startPoint);\n    }", "javadoc_start_line": 102, "annotations_start_line": 103, "method_start_line": 104, "end_line": 106}, {"file_path": "/src/main/java/org/apache/commons/math3/optimization/direct/BaseAbstractMultivariateOptimizer.java", "method_name": "optimizeInternal", "content": "    /**\n     * Optimize an objective function.\n     *\n     * @param f Objective function.\n     * @param goalType Type of optimization goal: either\n     * {@link GoalType#MAXIMIZE} or {@link GoalType#MINIMIZE}.\n     * @param startPoint Start point for optimization.\n     * @param maxEval Maximum number of function evaluations.\n     * @return the point/value pair giving the optimal value for objective\n     * function.\n     * @throws org.apache.commons.math3.exception.DimensionMismatchException\n     * if the start point dimension is wrong.\n     * @throws org.apache.commons.math3.exception.TooManyEvaluationsException\n     * if the maximal number of evaluations is exceeded.\n     * @throws org.apache.commons.math3.exception.NullArgumentException if\n     * any argument is {@code null}.\n     */\n    protected PointValuePair optimizeInternal(int maxEval, MultivariateFunction f, GoalType goalType,\n                                              double[] startPoint) {\n        // Checks.\n        if (f == null) {\n            throw new NullArgumentException();\n        }\n        if (goalType == null) {\n            throw new NullArgumentException();\n        }\n        if (startPoint == null) {\n            throw new NullArgumentException();\n        }\n\n        // Reset.\n        evaluations.setMaximalCount(maxEval);\n        evaluations.resetCount();\n\n        // Store optimization problem characteristics.\n        function = f;\n        goal = goalType;\n        start = startPoint.clone();\n\n        // Perform computation.\n        return doOptimize();\n    }", "javadoc_start_line": 108, "annotations_start_line": 125, "method_start_line": 126, "end_line": 149}, {"file_path": "/src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java", "method_name": "doOptimize", "content": "    /** {@inheritDoc} */\n    @Override\n    protected PointValuePair doOptimize() {\n        checkParameters();\n         // -------------------- Initialization --------------------------------\n        isMinimize = getGoalType().equals(GoalType.MINIMIZE);\n        final FitnessFunction fitfun = new FitnessFunction();\n        final double[] guess = fitfun.encode(getStartPoint());\n        // number of objective variables/problem dimension\n        dimension = guess.length;\n        initializeCMA(guess);\n        iterations = 0;\n        double bestValue = fitfun.value(guess);\n        push(fitnessHistory, bestValue);\n        PointValuePair optimum = new PointValuePair(getStartPoint(),\n                isMinimize ? bestValue : -bestValue);\n        PointValuePair lastResult = null;\n\n        // -------------------- Generation Loop --------------------------------\n\n        generationLoop:\n            for (iterations = 1; iterations <= maxIterations; iterations++) {\n                // Generate and evaluate lambda offspring\n                RealMatrix arz = randn1(dimension, lambda);\n                RealMatrix arx = zeros(dimension, lambda);\n                double[] fitness = new double[lambda];\n                // generate random offspring\n                for (int k = 0; k < lambda; k++) {\n                    RealMatrix arxk = null;\n                    for (int i = 0; i < checkFeasableCount+1; i++) {\n                        if (diagonalOnly <= 0) {\n                            arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k))\n                                    .scalarMultiply(sigma)); // m + sig * Normal(0,C)\n                        } else {\n                            arxk = xmean.add(times(diagD,arz.getColumnMatrix(k))\n                                    .scalarMultiply(sigma));\n                        }\n                        if (i >= checkFeasableCount || fitfun.isFeasible(arxk.getColumn(0))) {\n                            break;\n                        }\n                        // regenerate random arguments for row\n                        arz.setColumn(k, randn(dimension));\n                    }\n                    copyColumn(arxk, 0, arx, k);\n                    try {\n                        fitness[k] = fitfun.value(arx.getColumn(k)); // compute fitness\n                    } catch (TooManyEvaluationsException e) {\n                        break generationLoop;\n                    }\n                }\n                // Sort by fitness and compute weighted mean into xmean\n                int[] arindex = sortedIndices(fitness);\n                // Calculate new xmean, this is selection and recombination\n                RealMatrix xold = xmean; // for speed up of Eq. (2) and (3)\n                RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\n                xmean = bestArx.multiply(weights);\n                RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\n                RealMatrix zmean = bestArz.multiply(weights);\n                boolean hsig = updateEvolutionPaths(zmean, xold);\n                if (diagonalOnly <= 0) {\n                    updateCovariance(hsig, bestArx, arz, arindex, xold);\n                } else {\n                    updateCovarianceDiagonalOnly(hsig, bestArz, xold);\n                }\n                // Adapt step size sigma - Eq. (5)\n                sigma *= Math.exp(Math.min(1.0,(normps/chiN - 1.)*cs/damps));\n                double bestFitness = fitness[arindex[0]];\n                double worstFitness = fitness[arindex[arindex.length-1]];\n                if (bestValue > bestFitness) {\n                    bestValue = bestFitness;\n                    lastResult = optimum;\n                    optimum = new PointValuePair(\n                            fitfun.repairAndDecode(bestArx.getColumn(0)),\n                            isMinimize ? bestFitness : -bestFitness);\n                    if (getConvergenceChecker() != null && lastResult != null) {\n                        if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\n                            break generationLoop;\n                        }\n                    }\n                }\n                // handle termination criteria\n                // Break, if fitness is good enough\n                if (stopFitness != 0) { // only if stopFitness is defined\n                    if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {\n                        break generationLoop;\n                    }\n                }\n                double[] sqrtDiagC = sqrt(diagC).getColumn(0);\n                double[] pcCol = pc.getColumn(0);\n                for (int i = 0; i < dimension; i++) {\n                    if (sigma*(Math.max(Math.abs(pcCol[i]), sqrtDiagC[i])) > stopTolX) {\n                        break;\n                    }\n                    if (i >= dimension-1) {\n                        break generationLoop;\n                    }\n                }\n                for (int i = 0; i < dimension; i++) {\n                    if (sigma*sqrtDiagC[i] > stopTolUpX) {\n                        break generationLoop;\n                    }\n                }\n                double historyBest = min(fitnessHistory);\n                double historyWorst = max(fitnessHistory);\n                if (iterations > 2 && Math.max(historyWorst, worstFitness) -\n                        Math.min(historyBest, bestFitness) < stopTolFun) {\n                    break generationLoop;\n                }\n                if (iterations > fitnessHistory.length &&\n                        historyWorst-historyBest < stopTolHistFun) {\n                    break generationLoop;\n                }\n                // condition number of the covariance matrix exceeds 1e14\n                if (max(diagD)/min(diagD) > 1e7) {\n                    break generationLoop;\n                }\n                // user defined termination\n                if (getConvergenceChecker() != null) {\n                    PointValuePair current =\n                        new PointValuePair(bestArx.getColumn(0),\n                                isMinimize ? bestFitness : -bestFitness);\n                    if (lastResult != null &&\n                        getConvergenceChecker().converged(iterations, current, lastResult)) {\n                        break generationLoop;\n                    }\n                    lastResult = current;\n                }\n                // Adjust step size in case of equal function values (flat fitness)\n                if (bestValue == fitness[arindex[(int)(0.1+lambda/4.)]]) {\n                    sigma = sigma * Math.exp(0.2+cs/damps);\n                }\n                if (iterations > 2 && Math.max(historyWorst, bestFitness) -\n                        Math.min(historyBest, bestFitness) == 0) {\n                    sigma = sigma * Math.exp(0.2+cs/damps);\n                }\n                // store best in history\n                push(fitnessHistory,bestFitness);\n                fitfun.setValueRange(worstFitness-bestFitness);\n                if (generateStatistics) {\n                    statisticsSigmaHistory.add(sigma);\n                    statisticsFitnessHistory.add(bestFitness);\n                    statisticsMeanHistory.add(xmean.transpose());\n                    statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));\n                }\n            }\n        return optimum;\n    }", "javadoc_start_line": 347, "annotations_start_line": 348, "method_start_line": 349, "end_line": 493}]}], "project": {"name": "Math", "version": 20}}